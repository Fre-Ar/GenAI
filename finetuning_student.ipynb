{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66963437-f91e-4c45-a6c1-8863cad536cf",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### Install necessary library and dataset\n",
    "- if you don't have git you directly download it from https://github.com/srohit0/food_mnist.git with your browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e3287a-2672-4f2b-9429-50c4c2aa4a50",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install torch torchvision pillow requests opencv-python matplotlib\n",
    "!git clone https://github.com/srohit0/food_mnist.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ecba6b4-b2c5-4bd4-91b4-668753b59148",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### Import all necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf7fe14-c080-4c3e-b3be-c402ecd06287",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import food_mnist\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import torch, numpy\n",
    "import torch\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "import requests\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import time\n",
    "from torch.utils.data import Subset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39eaf48b-d839-40a0-a679-881867bbf479",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "###Â Functions to manipulate images with the right format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc48560-0afd-4c0b-b913-66a0a05ab71e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define preprocessing operations for images since \n",
    "#the pretrained model expects 224x224 images normalized with ImageNet stats\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),        # Resize shortest side to 224x224\n",
    "    transforms.ToTensor(),                # Convert to PyTorch tensor\n",
    "    transforms.Normalize(                 # Normalize using ImageNet means/stds\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    ),\n",
    "])\n",
    "def preprocess_images(x):\n",
    "    return torch.stack([preprocess(Image.fromarray(img.astype('uint8'))) for img in x])\n",
    "\n",
    "#Display an image with its title (rebuild the image from tensors)\n",
    "def imshow(img_tensor, title=None):\n",
    "    img = img_tensor.cpu().numpy().transpose(1,2,0)  # C,H,W -> H,W,C\n",
    "    img = img * np.array([0.229,0.224,0.225]) + np.array([0.485,0.456,0.406])  # unnormalize\n",
    "    img = np.clip(img, 0, 1)\n",
    "    plt.imshow(img)\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f21dde-2305-49b3-97ee-5223e01b2d90",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### Functions to evaluate a model\n",
    "- on a single image (predefined)\n",
    "- on a single batch (of size 8 showing in a grid the images)\n",
    "- on the full test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bb89d1-59d3-4503-8f75-54902af2c699",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Need the categories/labels used\n",
    "def test_single_image(model,categories):\n",
    "    image_path = \"food_mnist/images/apple_pie/118237.jpg\"  # replace with your image path\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    # Apply preprocessing\n",
    "    input_tensor = preprocess(image).unsqueeze(0)  # Add a batch dimension for a single image\n",
    "\n",
    "    #Run inference\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_tensor.to(device))\n",
    "        #special case as we have a single image here, we do the softmax on the full batch so dim=0\n",
    "        probabilities = torch.nn.functional.softmax(outputs[0], dim=0)\n",
    "\n",
    "    \n",
    "\n",
    "    # Get top-5 predictions\n",
    "    top5_prob, top5_catid = torch.topk(probabilities, 5)\n",
    "\n",
    "    print(\"\\nTop 5 Predictions:\")\n",
    "    for i in range(top5_prob.size(0)):\n",
    "        print(f\"{categories[top5_catid[i]]}: {top5_prob[i].item() * 100:.2f}%\")\n",
    "\n",
    "    # show image\n",
    "    image.show()\n",
    "\n",
    "#Need the categories/labels used\n",
    "def test_batch(model,images,categories):\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(images.to(device))\n",
    "        probs = torch.nn.functional.softmax(outputs, dim=1)\n",
    "        top_prob, top_catid = torch.topk(probs, 1)\n",
    "        # !!! Now we have run the inference for a batch, so softmax we done for each image in the batch... so the function above return a set of probablities and categories !\n",
    "\n",
    "        plt.figure(figsize=(12,6))\n",
    "        for i in range(my_batch_size):\n",
    "            plt.subplot(2,4,i+1)\n",
    "            title = f\"Top-1: {categories[top_catid[i][0]]}\\nConf: {top_prob[i][0]*100:.1f}%\"\n",
    "            imshow(images[i], title)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "#Categories are again the mapping of neural net output with ccategories\n",
    "#true_label are label as stated in the dataset (ground_truth)\n",
    "def test_all(model,images,categories,true_labels):   \n",
    "    total_correct = 0\n",
    "    total_images = 0\n",
    "\n",
    "    #Food dataset provides grountrth as numeric label, we need to get their text values (check github repo of the dataset)\n",
    "    food_labels = [\"apple pie\",\"baby back ribs\",\"baklava\",\"beef carpaccio\",\"beef tartare\",\"beet salad\",\"beignets\",\"bibimbap\",\"bread pudding\",\"breakfast burrito\"]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (images, labels) in enumerate(test_loader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            probs = torch.nn.functional.softmax(outputs, dim=1)\n",
    "            top_prob, top_catid = torch.max(probs, 1)\n",
    "    \n",
    "            total_images +=len(images)\n",
    "            \n",
    "            for i in range(len(images)):\n",
    "                #Get predicted label and comapre to the real one\n",
    "                #predict_label = imagenet_labels[top_catid[i][0]]\n",
    "                true_label = food_labels[labels[i].item()]         # ground-truth\n",
    "                pred_class = categories[top_catid[i].item()]    # predicted class\n",
    "           \n",
    "                if true_label == pred_class:\n",
    "                    total_correct+=1\n",
    "        \n",
    "    accuracy = total_correct / total_images * 100\n",
    "    print(f\"Total correct predictions: {total_correct}/{total_images}\")\n",
    "    print(f\"Overall test accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8895a7d-52fc-4b9f-b454-1c89d78b63e5",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### No fine-tuning\n",
    "1. Load the pre-trained model\n",
    "2. Load the dataset and format it as tensors in data loader\n",
    "3. Test the first batch of data and display it with pictures\n",
    "4. Test on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6acf09e3-8eaf-439b-a998-05c6db3f9cc7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load ResNet-18 with pretrained weights on ImageNet\n",
    "model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "model.to(device)\n",
    "model.eval()  # Set model to evaluation mode (important for inference)\n",
    "\n",
    "param_size = sum(p.numel() * p.element_size() for p in model.parameters())\n",
    "buffer_size = sum(b.numel() * b.element_size() for b in model.buffers())\n",
    "total_size = (param_size + buffer_size) / 1024**2  # Convert to MB\n",
    "\n",
    "#Show mode size\n",
    "print(f\"Model size: {total_size:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c9ff04-c61d-42d0-b2a1-af6ae618ed71",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#load data\n",
    "(x_train, y_train), (x_test, y_test) = food_mnist.load_data(224,224)\n",
    "\n",
    "# Convert all images from BGR to RGB\n",
    "x_train = x_train[:,:,:,:][:,:,:,::-1].copy()\n",
    "x_test  = x_test[:,:,:,:][:,:,:,::-1].copy()\n",
    "\n",
    "#create tensors\n",
    "#Uses only 128 images for test (you can change this value below (up to 1250)\n",
    "x_train_tensor = preprocess_images(x_train)\n",
    "y_train_tensor = torch.tensor(y_train)\n",
    "x_test_tensor  = preprocess_images(x_test[:128])\n",
    "y_test_tensor  = torch.tensor(y_test[:128])\n",
    "\n",
    "\n",
    "\n",
    "#create data loaders\n",
    "my_batch_size=8\n",
    "\n",
    "#Create the tensor dataset and make it ready for use with a batch size of 8 (can be changed)\n",
    "test_dataset = TensorDataset(x_test_tensor, y_test_tensor)\n",
    "test_loader = DataLoader(test_dataset, my_batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "print(\"############## No fine-tuning ##############\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd57929-8b99-4957-acb9-1b64218aeb13",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "- Test on a single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d03cdc8-39ac-474e-b868-e6678a3d3e66",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Decode prediction\n",
    "# Get ImageNet class labels\n",
    "# (torchvision provides them through the weights metadata)\n",
    "categories = models.ResNet18_Weights.IMAGENET1K_V1.meta[\"categories\"]\n",
    "\n",
    "#Test a single image\n",
    "test_single_image(model,categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932eca3d-d86b-4e8f-a320-b57ce7514b89",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "- Test on a single batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26869ec3-ea43-4dcb-8775-707d205bd749",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Test the first batch of test data and get the top probabilities and top categories/labels\n",
    "images, labels = next(iter(test_loader))\n",
    "\n",
    "# Get ImageNet class labels\n",
    "# (torchvision provides them through the weights metadata)\n",
    "categories = models.ResNet18_Weights.IMAGENET1K_V1.meta[\"categories\"]\n",
    "test_batch(model,images,categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ff0777-6f34-47d7-a3a2-b4651e938cb6",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "- Test on the test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd54f66-e06d-4f13-9c58-6782f4ba5b75",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "images, labels = next(iter(test_loader))\n",
    "\n",
    "# Get ImageNet class labels\n",
    "# (torchvision provides them through the weights metadata)\n",
    "categories = models.ResNet18_Weights.IMAGENET1K_V1.meta[\"categories\"]\n",
    "\n",
    "#WHat are the true labels of the dataset, check for the dataset online or in food_mnist directory \n",
    "true_labels = [\"apple pie\",\"baby back ribs\",\"baklava\",\"beef carpaccio\",\"beef tartare\",\"beet salad\",\"beignets\",\"bibimbap\",\"bread pudding\",\"breakfast burrito\"]\n",
    "\n",
    "test_all(model,images,categories,true_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada663cf-0f29-4562-b056-5004b353294f",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### Load a fine-tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffa319e-9cb5-4cca-9da7-aa0ea920a2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !!! TODO\n",
    "#use torch.load function similar to the pre-trained model\n",
    "#using the given fine-tuned model \n",
    "\n",
    "\n",
    "\n",
    "sft_model.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d243fe5e-b3dd-46e4-a33b-2470ad5bd345",
   "metadata": {},
   "source": [
    "- Test the model using the different test functions\n",
    "- Note: the model has been fine-tune according to the category of the MNIST food dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ad1561-213b-45af-88f1-fe43f2659d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval() \n",
    "\n",
    "#!!!! TODO here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d25933-2381-4169-aa97-7f5d18a67f7e",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### Fine-tune your model\n",
    "1. replace the feed-forward network head (fully connected layer)  by a new linear model according to the number of class\n",
    "2. makes all parameters trainable\n",
    "3. configure optimizer. You can adjust the different parameters and see the impact on performance\n",
    "4. Select a subset of training data (faster). You can adjust this parameter and see the impact\n",
    "5. Train your model\n",
    "6. Save your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9ae78f-8437-4302-9b00-724980da4eea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"############## Fine-tuning ##############\")\n",
    "\n",
    "num_classes = 10  # Food-MNIST\n",
    "\n",
    "# Replace the final layer named fc in ResNet-18 (fc for fully connected) and in_features is the size of the input vector)\n",
    "# !! TODO: the code below needs to be completed\n",
    "print(model.fc) #original model\n",
    "model.fc = nn.Linear(model.fc.....)\n",
    "print(model.fc) #fine-tuned model (not yet fine-tuned)\n",
    "\n",
    "# Keep all layers trainable (full fine-tuning)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True  # make sure all layers are updated\n",
    "\n",
    "\n",
    "#Configure the optimization\n",
    "# !! TODO You can change the learning rate or the number of epochs\n",
    "criterion = nn.CrossEntropyLoss() #usual metric for classification\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-2) \n",
    "num_epochs = 5\n",
    "\n",
    "\n",
    "start_time = time.time()  # record overall start time\n",
    "\n",
    "train_dataset = TensorDataset(x_train_tensor, y_train_tensor)\n",
    "# Choose a subset size, e.g. 10% of the training set\n",
    "subset_size = int(1.0 * len(train_dataset))  # 10%\n",
    "\n",
    "# Randomly select subset indices\n",
    "subset_indices = np.random.choice(len(train_dataset), subset_size, replace=False)\n",
    "\n",
    "# Create subset dataset\n",
    "train_subset = Subset(train_dataset, subset_indices)\n",
    "train_loader = torch.utils.data.DataLoader(train_subset, batch_size=32, shuffle=True)\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - Loss: {running_loss/total:.4f} - Acc: {correct/total*100:.3f}%\")\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(f\"Total training time: {total_time/60:.2f} minutes ({total_time:.1f} seconds)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcaa9ebf-8e3c-4037-bb81-35cafa267bfd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.eval() \n",
    "\n",
    "## !! TODO evaluate the model on a single image, single batch and full test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4ad248-f3a8-4383-b149-09f13248a866",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"my_first_sft_model.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai-env",
   "language": "python",
   "name": "genai-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
